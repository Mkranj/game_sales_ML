---
title: "Model showcase"
output: html_document
date: "2023-11-19"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
source("1_load.R")
```
# Visualisations

```{r}
library(ggplot2)
ggplot(games, aes(x = NA_Sales)) + geom_histogram()
```

Overview without extremes

```{r}

ggplot(games %>% 
         filter(NA_Sales < 2), 
       aes(x = NA_Sales)) + geom_histogram()
```
```{r}

ggplot(games %>% 
         filter(NA_Sales < 0.5), 
       aes(x = NA_Sales)) + geom_histogram()
```

# Exploring game names
```{r}
game_names <- games$Name
table(game_names)[sample(1:length(game_names), 15)]
# Games with same name on multiple consoles counted as two!!!
```
```{r}
library(stringr)
separator_colon <- stringr::str_detect(game_names, ": ")
separator_line <- stringr::str_detect(game_names, " - ")

# Count as having a subtitle if any match
subtitled <- separator_colon | separator_line

# Some names could have multiple subtitles! Is that even worse?
colon_count <- stringr::str_count(game_names, ": ") 

# Making it into variables:
games$subtitled_name <- subtitled
games$subtitle_colon_count <- colon_count
```

```{r}
by_subtitle <- group_by(games, subtitled_name) %>%
  summarise(avg = mean(NA_Sales), 
            std = sd(NA_Sales),
            no = n())

no_subtitles <- group_by(games, subtitle_colon_count) %>%
  summarise(avg = mean(NA_Sales), 
            std = sd(NA_Sales),
            no = n())

# Actually BOTH hold!!!
print(by_subtitle)
print(no_subtitles)
```


# Modelling

Training-testing split
```{r}
tt_split <- initial_split(games)

tt_training <- training(tt_split)
tt_testing <- testing(tt_split)

```

Feature engineering

```{r}
dev_summary <- calculate_dev_summaries(tt_training)

tt_training$Top_performer_dev <- 
  mark_top_performer_dev(input_df = tt_training,
                         summarised_df = dev_summary,
                         summary_metric = "avg_income",
                         n_top = 10) |> 
  as.factor()

tt_testing$Top_performer_dev <- 
  mark_top_performer_dev(input_df = tt_testing,
                         summarised_df = dev_summary,
                         summary_metric = "avg_income",
                         n_top = 10) |> 
  as.factor()

tt_training$Dev_games_made <- 
  mark_top_performer_dev(input_df = tt_training,
                         summarised_df = dev_summary,
                         summary_metric = "no_games",
                         n_top = 10) |> 
  as.factor()

tt_testing$Dev_games_made <- 
  mark_top_performer_dev(input_df = tt_testing,
                         summarised_df = dev_summary,
                         summary_metric = "no_games",
                         n_top = 10) |> 
  as.factor()
```


Model definition

```{r}
library(recipes)
# Define variables to be used
predictors <- c("Year_release_n", "Genre_F", "Rating_F", "Top_performer_dev", "Dev_games_made")
criterium <- "Global_Sales"

model_formula <- paste0(criterium, " ~ ",
                        paste(predictors, collapse = " + ")) |> 
  formula()

model_recipe <- recipe(model_formula, data = tt_training) |> 
# Imputing missing values
  # TODO missing za top perf treba biti F, za Rating i Genre other?
  step_impute_median(Year_release_n) |> 
  step_impute_mode(all_nominal())

# Postprocessing - can't be negative

linear_model <- linear_reg()
```

Fit model

```{r}
model_workflow <- workflow() |>
  add_model(linear_model) |> 
  add_recipe(model_recipe)
fitted_model <- model_workflow |> fit(tt_training)

# Metrics



training_results <- tt_testing |> 
  #select(Global_Sales) |> 
  bind_cols(
    predict(fitted_model, new_data = tt_testing[, predictors])
  )

# show that all the preprocessing steps are applied to the testing data too
# (at predict() stage)
#prep(model_recipe) |>  bake(new_data = tt_testing)

training_results |> metrics(truth = Global_Sales, estimate = .pred)

```

Historic:
"Year_release_n", "Genre_F", "Rating_F", "Top_performer_dev", "Dev_games_made"
linear model
rsq 18.9%
mae 0.56

random forest
rsq 29%
mae 0.53