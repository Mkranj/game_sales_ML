---
title: "Model showcase"
output: html_document
date: "2023-11-19"
---

Predicting global game sales by video game characteristics.

An interesting model will showcase some underlying characteristics that could be
unexpectedly linked to sale numbers. Of course, true precision, unexpected smash
hits are very difficult to predict. However, this might shed light on some
attributes that normally wouldn't even be considered - e.g. game title
characteristics.

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
source("feature_engineering_fn.R")
source("post_process_fn.R")
source("visualisation_fn.R")
```
```{r}
source("1_load.R")
```

# Visualisations

```{r}
library(ggplot2)
ggplot(games, aes(x = Global_Sales)) + geom_histogram()
```

Overview without extremes

```{r}
ggplot(games %>% 
         filter(Global_Sales < 10000000), 
       aes(x = Global_Sales)) + geom_histogram()
```
```{r}

ggplot(games %>% 
         filter(Global_Sales < 1000000), 
       aes(x = Global_Sales)) + geom_histogram()
```
Log transform sales
```{r}
ggplot(games, aes(x = log10(Global_Sales))) + geom_histogram()
```
Log transformed data looks much more normal. Let's use log transformation for our targets.

By years of release
```{r}
ggplot_discrete_polynomials(games, "Year_release_n", "Global_Sales")
```

```{r}
games$Global_Sales_log <- log10(games$Global_Sales)
```


# Sales and number of consoles released on
```{r}
sales_by_cons_no <- group_by(games, Consoles_no) %>%
  summarise(average = mean(Global_Sales_log),
            count = n()
  ) %>%
  mutate(average_per_console = average/Consoles_no)

ggplot(sales_by_cons_no, aes(x = Consoles_no, y = average)) +
  geom_point(aes(size = count)) + scale_x_continuous(breaks = 1:20)

ggplot(sales_by_cons_no, aes(x = Consoles_no, y = average_per_console)) + geom_point(aes(size = count)) + scale_x_continuous(breaks = 1:20)
# Not linear - polynomial might helps predictions
```
```{r}
# Draw a smooth line considering all points, and polyinomial of a given level.
# Summary "dots" in the background for easier viewing

ggplot_discrete_polynomials(games, "Consoles_no", "Global_Sales_log", poly_degree = 1)
ggplot_discrete_polynomials(games, "Consoles_no", "Global_Sales_log", poly_degree = 2)
ggplot_discrete_polynomials(games, "Consoles_no", "Global_Sales_log", poly_degree = 3)
```

# Exploring game names
```{r}
game_names <- games$Name
subtitles <- count_subtitles(game_names)

# Making it into variables:
games$has_subtitle <- subtitles$subtitle_present
games$subtitle_count <- subtitles$subtitle_count
```

```{r}
by_subtitle <- group_by(games, has_subtitle) %>%
  summarise(avg = mean(Global_Sales_log), 
            std = sd(Global_Sales_log),
            no = n())

no_subtitles <- group_by(games, subtitle_count) %>%
  summarise(avg = mean(Global_Sales_log), 
            std = sd(Global_Sales_log),
            no = n())

# Actually BOTH hold!!!
print(by_subtitle)
print(no_subtitles)
```
Detect unusual titles  
Those with non-alphanumeric symbols - count how many there are
```{r}
games$unusual_title_symbols <- games$Name %>% count_unusual_symbols()
```

```{r}
unusual_titles <- group_by(games, unusual_title_symbols) %>%
  summarise(avg = mean(Global_Sales_log), 
            std = sd(Global_Sales_log),
            no = n())

unusual_titles 
```

```{r}
ggplot_discrete_polynomials(games, 
                            "unusual_title_symbols", "Global_Sales_log",
                            poly_degree = 1)
ggplot_discrete_polynomials(games, 
                            "unusual_title_symbols", "Global_Sales_log",
                            poly_degree = 2)
ggplot_discrete_polynomials(games, 
                            "unusual_title_symbols", "Global_Sales_log",
                            poly_degree = 3)
```

This does appear to lower sales. One degree should be enough.

Title wordcount
```{r}
ggplot_discrete_polynomials(games, "Title_words", "Global_Sales_log", 1)
```
Title length
```{r}
ggplot_discrete_polynomials(games, "Title_length", "Global_Sales_log", 1)
ggplot_discrete_polynomials(games, "Title_length", "Global_Sales_log", 2)
```
Second level polynomial could be useful

Interaction of wordcount and length
```{r}
ggplot(games, aes(x = Title_length, y = Title_words)) +
  geom_jitter(
    aes(color = Global_Sales_log),
    # Amount to jitter the points for better overview
    width = 0.2, height = 0.4)
```
It's hard to see a pattern, interaction probably wouldn't increase prediction accuraccy.

## By console
```{r}
for (console in console_colnames) {
  group_by(games, .data[[console]]) %>% summarise(avg = mean(Global_Sales_log), 
            std = sd(Global_Sales_log),
            no = n()) %>% print()
}
```


# Modelling
Criterium: Global sales

Training-testing split
```{r}
tt_split <- initial_split(games)

tt_training <- training(tt_split)
tt_testing <- testing(tt_split)

```

Feature engineering

```{r}
dev_summary <- calculate_dev_summaries(tt_training)
head(dev_summary)
```

```{r}
# Join games' dev avg_income and games made total

# Special object for joining, just adjust variable names to start with dev_
devs_join <- dev_summary %>%
  rename_with( ~ paste0("dev_", .x))

tt_training <- left_join(tt_training, devs_join, by = c("Developer" = "dev_Developer"))
tt_testing <- left_join(tt_testing, devs_join, by = c("Developer" = "dev_Developer"))
```

```{r}
# ADJUSTMENT
# if developers are not recognised, set avg_sales and games made to zero!
# Seems more sensical than using the median to imput - if the dev team is
# small, they should get lower values here

tt_training <- tt_training %>% missing_to_zero("dev_avg_income")
tt_training <- tt_training %>% missing_to_zero("dev_no_games")

tt_testing <- tt_testing %>% missing_to_zero("dev_avg_income")
tt_testing <- tt_testing %>% missing_to_zero("dev_no_games")
```


Visualisation of sales by dev characteristics
```{r}
ggplot(tt_training, aes(x = dev_avg_income, y = Global_Sales_log)) + geom_point() +
  geom_smooth()


ggplot(tt_training, aes(x = dev_no_games, y = Global_Sales_log)) + geom_point() +
  geom_smooth()
```
Average income correlates with global sales, of course. Number of games made not so much.

```{r}
# Is the game developed by a dev that's top 10 by income, or by
# amount of games made?

# NOT USED IN MODEL ANYMORE

tt_training$Top_performer_dev <- 
  mark_top_performer_dev(input_df = tt_training,
                         summarised_df = dev_summary,
                         summary_metric = "avg_income",
                         n_top = 10) %>% 
  as.factor()

tt_testing$Top_performer_dev <- 
  mark_top_performer_dev(input_df = tt_testing,
                         summarised_df = dev_summary,
                         summary_metric = "avg_income",
                         n_top = 10) %>% 
  as.factor()

tt_training$Dev_games_made <- 
  mark_top_performer_dev(input_df = tt_training,
                         summarised_df = dev_summary,
                         summary_metric = "no_games",
                         n_top = 10) %>% 
  as.factor()

tt_testing$Dev_games_made <- 
  mark_top_performer_dev(input_df = tt_testing,
                         summarised_df = dev_summary,
                         summary_metric = "no_games",
                         n_top = 10) %>% 
  as.factor()
```

Squared number of Consoles released on
```{r}
tt_training$Consoles_no_sq <- tt_training$Consoles_no ** 2
tt_testing$Consoles_no_sq <- tt_testing$Consoles_no ** 2
```

Cross validation for the training set
```{r}
set.seed(1234)
tt_folds <- vfold_cv(tt_training, v = 10)
```


Model definition

```{r}
library(recipes)
# Define variables to be used
predictors <- c("Year_release_n", "Genre_F", "Rating_F", "dev_avg_income",  "subtitle_count",
                console_colnames, "Consoles_no", "unusual_title_symbols",
                "Title_words", "Title_length")
criterium <- "Global_Sales_log"

predictors_to_center <- c("Year_release_n", "dev_avg_income", "unusual_title_symbols", "Title_words", "Title_length")

model_formula <- paste0(criterium, " ~ ",
                        paste(predictors, collapse = " + ")) %>% 
  formula()

model_recipe <- recipe(model_formula, data = tt_training) %>% 
  step_impute_median(Year_release_n) %>% 
  step_impute_mode(all_nominal()) %>% 
  step_dummy(all_factor_predictors()) %>% 
  step_poly(Consoles_no, degree = 2) %>%
  step_poly(subtitle_count, degree = 2) %>%
  step_center(predictors_to_center,
              starts_with(c("Consoles_no", "subtitle_count"))
              ) %>% 
  step_scale(predictors_to_center,
             starts_with(c("Consoles_no", "subtitle_count"))
             )

# Postprocessing - can't be negative
```

Algorithms to consider

```{r}
linear_model <- linear_reg()
random_forest_model <- rand_forest(mode = "regression", engine = "ranger")
svm_model <- svm_linear(mode = "regression", engine = "LiblineaR")
```

Fit models

```{r}
model_workflow_linear <- workflow() %>%
  add_model(linear_model) %>% 
  add_recipe(model_recipe)

fitted_cv <- fit_resamples(model_workflow_linear, tt_folds,
                           metrics = metric_set(rmse, rsq, mae))

# Get the averaged metrics for the 10fold CV
metrics_folds_linear <- collect_metrics(fitted_cv)
metrics_folds_linear
```

```{r}
model_workflow_rf <- workflow() %>%
  add_model(random_forest_model) %>% 
  add_recipe(model_recipe)

fitted_cv <- fit_resamples(model_workflow_rf, tt_folds,
                           metrics = metric_set(rmse, rsq, mae))

# Get the averaged metrics for the 10fold CV
metrics_folds_rf <- collect_metrics(fitted_cv)
metrics_folds_rf
```

```{r}
# TODO - process data in form acceptable for svm

# model_workflow_svm <- workflow() %>%
#   add_model(svm_model) %>% 
#   add_recipe(model_recipe)
# 
# fitted_cv <- fit_resamples(model_workflow_svm, tt_folds,
#                            metrics = metric_set(rmse, rsq, mae))

# Get the averaged metrics for the 10fold CV
# metrics_folds_svm <- collect_metrics(fitted_cv)
# metrics_folds_svm
```

```{r}
fitted_model <- model_workflow_rf %>% fit(tt_training)

# Metrics



training_results <- tt_testing %>% 
  #select(Global_Sales_log) %>% 
  bind_cols(
    predict(fitted_model, new_data = tt_testing[, predictors])
  ) %>%
  adjust_negative_preds()

training_results %>% metrics(truth = Global_Sales_log, estimate = .pred)

```

Metrics when back-transformed from log
```{r}
training_results %>%
  # Transform predictions to actual number sold
  mutate(pred_exp = 10 ** .pred) %>%
  metrics(truth = Global_Sales, estimate = pred_exp)
```


Testing data with augmented features
```{r}
prep(model_recipe) %>%
  bake(new_data = tt_testing) %>%
  bind_cols(
    predict(fitted_model, new_data = tt_testing[, predictors])
  ) %>%
  adjust_negative_preds()
```