---
title: "Model showcase"
output: html_document
date: "2023-11-19"
---

Predicting global game sales by video game characteristics.

An interesting model will showcase some underlying characteristics that could be
unexpectedly linked to sale numbers. Of course, true precision, unexpected smash
hits are very difficult to predict. However, this might shed light on some
attributes that normally wouldn't even be considered - e.g. game title
characteristics.

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
source("1_load.R")
source("feature_engineering_fn.R")
source("post_process_fn.R")
```
# Visualisations

```{r}
library(ggplot2)
ggplot(games, aes(x = Global_Sales)) + geom_histogram()
```

Overview without extremes

```{r}

ggplot(games %>% 
         filter(Global_Sales < 2), 
       aes(x = Global_Sales)) + geom_histogram()
```
```{r}

ggplot(games %>% 
         filter(Global_Sales < 0.5), 
       aes(x = Global_Sales)) + geom_histogram()
```
# Sales and number of consoles released on
```{r}
sales_by_cons_no <- group_by(games, Consoles_no) %>%
  summarise(average = mean(Global_Sales),
            count = n()
  ) %>%
  mutate(average_per_console = average/Consoles_no)

ggplot(sales_by_cons_no, aes(x = Consoles_no, y = average)) +
  geom_point(aes(size = count)) + scale_x_continuous(breaks = 1:20)

ggplot(sales_by_cons_no, aes(x = Consoles_no, y = average_per_console)) + geom_point(aes(size = count)) + scale_x_continuous(breaks = 1:20)
# Not linear - polynomial might helps predictions
```


# Exploring game names
```{r}
game_names <- games$Name
subtitles <- count_subtitles(game_names)

# Making it into variables:
games$has_subtitle <- subtitles$subtitle_present
games$subtitle_count <- subtitles$subtitle_count
```

```{r}
by_subtitle <- group_by(games, has_subtitle) %>%
  summarise(avg = mean(Global_Sales), 
            std = sd(Global_Sales),
            no = n())

no_subtitles <- group_by(games, subtitle_count) %>%
  summarise(avg = mean(Global_Sales), 
            std = sd(Global_Sales),
            no = n())

# Actually BOTH hold!!!
print(by_subtitle)
print(no_subtitles)
```
## By console
```{r}
for (console in console_colnames) {
  group_by(games, .data[[console]]) %>% summarise(avg = mean(Global_Sales), 
            std = sd(Global_Sales),
            no = n()) %>% print()
}
```


# Modelling
Criterium: Global sales

Training-testing split
```{r}
tt_split <- initial_split(games)

tt_training <- training(tt_split)
tt_testing <- testing(tt_split)

```

Feature engineering

```{r}
dev_summary <- calculate_dev_summaries(tt_training)

tt_training$Top_performer_dev <- 
  mark_top_performer_dev(input_df = tt_training,
                         summarised_df = dev_summary,
                         summary_metric = "avg_income",
                         n_top = 10) |> 
  as.factor()

tt_testing$Top_performer_dev <- 
  mark_top_performer_dev(input_df = tt_testing,
                         summarised_df = dev_summary,
                         summary_metric = "avg_income",
                         n_top = 10) |> 
  as.factor()

tt_training$Dev_games_made <- 
  mark_top_performer_dev(input_df = tt_training,
                         summarised_df = dev_summary,
                         summary_metric = "no_games",
                         n_top = 10) |> 
  as.factor()

tt_testing$Dev_games_made <- 
  mark_top_performer_dev(input_df = tt_testing,
                         summarised_df = dev_summary,
                         summary_metric = "no_games",
                         n_top = 10) |> 
  as.factor()
```

Squared number of Consoles released on
```{r}
tt_training$Consoles_no_sq <- tt_training$Consoles_no ** 2
tt_testing$Consoles_no_sq <- tt_testing$Consoles_no ** 2
```


Model definition

```{r}
library(recipes)
# Define variables to be used
predictors <- c("Year_release_n", "Genre_F", "Rating_F", "Top_performer_dev",
                "Dev_games_made", "has_subtitle", "subtitle_count",
                console_colnames, "Consoles_no", "Consoles_no_sq")
criterium <- "Global_Sales"

predictors_to_center <- c("Year_release_n", "Consoles_no", "Consoles_no_sq")

model_formula <- paste0(criterium, " ~ ",
                        paste(predictors, collapse = " + ")) |> 
  formula()

model_recipe <- recipe(model_formula, data = tt_training) |> 
# Imputing missing values
  # TODO missing za top perf treba biti F, za Rating i Genre other?
  step_impute_median(Year_release_n) |> 
  step_impute_mode(all_nominal()) |> 
  step_dummy(all_factor_predictors()) |> 
  step_center(predictors_to_center) |> 
  step_scale(predictors_to_center)

# Postprocessing - can't be negative

linear_model <- linear_reg()
```

Fit model

```{r}
model_workflow <- workflow() |>
  add_model(linear_model) |> 
  add_recipe(model_recipe)
fitted_model <- model_workflow |> fit(tt_training)

# Metrics



training_results <- tt_testing |> 
  #select(Global_Sales) |> 
  bind_cols(
    predict(fitted_model, new_data = tt_testing[, predictors])
  ) |>
  adjust_negative_preds()

# show that all the preprocessing steps are applied to the testing data too
# (at predict() stage)
#prep(model_recipe) |>  bake(new_data = tt_testing)

training_results |> metrics(truth = Global_Sales, estimate = .pred)

```

Testing data with augmented features
```{r}
prep(model_recipe) %>%
  bake(new_data = tt_testing) %>%
  bind_cols(
    predict(fitted_model, new_data = tt_testing[, predictors])
  ) |>
  adjust_negative_preds()
```


Historic:
"Year_release_n", "Genre_F", "Rating_F", "Top_performer_dev", "Dev_games_made"
linear model
rsq 18.9%
mae 0.56

random forest
rsq 29%
mae 0.53